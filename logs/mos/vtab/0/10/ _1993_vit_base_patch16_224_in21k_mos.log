2024-01-15 15:36:24,960 [trainer.py] => config: ./exps/mos_vtab_in21k.json
2024-01-15 15:36:24,960 [trainer.py] => device: [device(type='cuda', index=1)]
2024-01-15 15:36:24,960 [trainer.py] => adapter_momentum: 0.1
2024-01-15 15:36:24,960 [trainer.py] => init_cls: 10
2024-01-15 15:36:24,960 [trainer.py] => increment: 10
2024-01-15 15:36:24,960 [trainer.py] => tuned_epoch: 20
2024-01-15 15:36:24,960 [trainer.py] => ensemble: True
2024-01-15 15:36:24,960 [trainer.py] => prefix:  
2024-01-15 15:36:24,960 [trainer.py] => dataset: vtab
2024-01-15 15:36:24,961 [trainer.py] => memory_size: 0
2024-01-15 15:36:24,961 [trainer.py] => memory_per_class: 0
2024-01-15 15:36:24,961 [trainer.py] => fixed_memory: False
2024-01-15 15:36:24,961 [trainer.py] => shuffle: False
2024-01-15 15:36:24,961 [trainer.py] => model_name: mos
2024-01-15 15:36:24,961 [trainer.py] => backbone_type: vit_base_patch16_224_in21k_mos
2024-01-15 15:36:24,961 [trainer.py] => seed: 1993
2024-01-15 15:36:24,961 [trainer.py] => init_lr: 0.03
2024-01-15 15:36:24,961 [trainer.py] => batch_size: 32
2024-01-15 15:36:24,961 [trainer.py] => weight_decay: 0.005
2024-01-15 15:36:24,961 [trainer.py] => min_lr: 0
2024-01-15 15:36:24,961 [trainer.py] => optimizer: sgd
2024-01-15 15:36:24,961 [trainer.py] => scheduler: cosine
2024-01-15 15:36:24,961 [trainer.py] => reinit_optimizer: True
2024-01-15 15:36:24,961 [trainer.py] => init_milestones: [10]
2024-01-15 15:36:24,961 [trainer.py] => init_lr_decay: 0.1
2024-01-15 15:36:24,961 [trainer.py] => reg: 0.1
2024-01-15 15:36:24,962 [trainer.py] => crct_epochs: 30
2024-01-15 15:36:24,962 [trainer.py] => ca_lr: 0.005
2024-01-15 15:36:24,962 [trainer.py] => ca_storage_efficient_method: covariance
2024-01-15 15:36:24,962 [trainer.py] => ca_storage_efficient_method_choices: ['covariance', 'multi-centroid', 'variance']
2024-01-15 15:36:24,962 [trainer.py] => n_centroids: 10
2024-01-15 15:36:24,962 [trainer.py] => pretrained: True
2024-01-15 15:36:24,962 [trainer.py] => drop: 0.0
2024-01-15 15:36:24,962 [trainer.py] => drop_path: 0.0
2024-01-15 15:36:24,962 [trainer.py] => ffn_num: 16
2024-01-15 15:36:25,021 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]
2024-01-15 15:36:29,307 [mos.py] => 86,141,426 model total parameters.
2024-01-15 15:36:29,308 [mos.py] => 342,770 model training parameters.
2024-01-15 15:36:29,308 [mos.py] => head.weight: 38400
2024-01-15 15:36:29,308 [mos.py] => head.bias: 50
2024-01-15 15:36:29,309 [mos.py] => cur_adapter.0.down_proj.weight: 12288
2024-01-15 15:36:29,309 [mos.py] => cur_adapter.0.down_proj.bias: 16
2024-01-15 15:36:29,309 [mos.py] => cur_adapter.0.up_proj.weight: 12288
2024-01-15 15:36:29,309 [mos.py] => cur_adapter.0.up_proj.bias: 768
2024-01-15 15:36:29,309 [mos.py] => cur_adapter.1.down_proj.weight: 12288
2024-01-15 15:36:29,309 [mos.py] => cur_adapter.1.down_proj.bias: 16
2024-01-15 15:36:29,309 [mos.py] => cur_adapter.1.up_proj.weight: 12288
2024-01-15 15:36:29,309 [mos.py] => cur_adapter.1.up_proj.bias: 768
2024-01-15 15:36:29,309 [mos.py] => cur_adapter.2.down_proj.weight: 12288
2024-01-15 15:36:29,309 [mos.py] => cur_adapter.2.down_proj.bias: 16
2024-01-15 15:36:29,309 [mos.py] => cur_adapter.2.up_proj.weight: 12288
2024-01-15 15:36:29,309 [mos.py] => cur_adapter.2.up_proj.bias: 768
2024-01-15 15:36:29,309 [mos.py] => cur_adapter.3.down_proj.weight: 12288
2024-01-15 15:36:29,309 [mos.py] => cur_adapter.3.down_proj.bias: 16
2024-01-15 15:36:29,309 [mos.py] => cur_adapter.3.up_proj.weight: 12288
2024-01-15 15:36:29,309 [mos.py] => cur_adapter.3.up_proj.bias: 768
2024-01-15 15:36:29,309 [mos.py] => cur_adapter.4.down_proj.weight: 12288
2024-01-15 15:36:29,309 [mos.py] => cur_adapter.4.down_proj.bias: 16
2024-01-15 15:36:29,309 [mos.py] => cur_adapter.4.up_proj.weight: 12288
2024-01-15 15:36:29,309 [mos.py] => cur_adapter.4.up_proj.bias: 768
2024-01-15 15:36:29,310 [mos.py] => cur_adapter.5.down_proj.weight: 12288
2024-01-15 15:36:29,310 [mos.py] => cur_adapter.5.down_proj.bias: 16
2024-01-15 15:36:29,310 [mos.py] => cur_adapter.5.up_proj.weight: 12288
2024-01-15 15:36:29,310 [mos.py] => cur_adapter.5.up_proj.bias: 768
2024-01-15 15:36:29,310 [mos.py] => cur_adapter.6.down_proj.weight: 12288
2024-01-15 15:36:29,310 [mos.py] => cur_adapter.6.down_proj.bias: 16
2024-01-15 15:36:29,310 [mos.py] => cur_adapter.6.up_proj.weight: 12288
2024-01-15 15:36:29,310 [mos.py] => cur_adapter.6.up_proj.bias: 768
2024-01-15 15:36:29,310 [mos.py] => cur_adapter.7.down_proj.weight: 12288
2024-01-15 15:36:29,310 [mos.py] => cur_adapter.7.down_proj.bias: 16
2024-01-15 15:36:29,310 [mos.py] => cur_adapter.7.up_proj.weight: 12288
2024-01-15 15:36:29,310 [mos.py] => cur_adapter.7.up_proj.bias: 768
2024-01-15 15:36:29,310 [mos.py] => cur_adapter.8.down_proj.weight: 12288
2024-01-15 15:36:29,310 [mos.py] => cur_adapter.8.down_proj.bias: 16
2024-01-15 15:36:29,310 [mos.py] => cur_adapter.8.up_proj.weight: 12288
2024-01-15 15:36:29,310 [mos.py] => cur_adapter.8.up_proj.bias: 768
2024-01-15 15:36:29,310 [mos.py] => cur_adapter.9.down_proj.weight: 12288
2024-01-15 15:36:29,310 [mos.py] => cur_adapter.9.down_proj.bias: 16
2024-01-15 15:36:29,310 [mos.py] => cur_adapter.9.up_proj.weight: 12288
2024-01-15 15:36:29,310 [mos.py] => cur_adapter.9.up_proj.bias: 768
2024-01-15 15:36:29,311 [mos.py] => cur_adapter.10.down_proj.weight: 12288
2024-01-15 15:36:29,311 [mos.py] => cur_adapter.10.down_proj.bias: 16
2024-01-15 15:36:29,311 [mos.py] => cur_adapter.10.up_proj.weight: 12288
2024-01-15 15:36:29,311 [mos.py] => cur_adapter.10.up_proj.bias: 768
2024-01-15 15:36:29,311 [mos.py] => cur_adapter.11.down_proj.weight: 12288
2024-01-15 15:36:29,311 [mos.py] => cur_adapter.11.down_proj.bias: 16
2024-01-15 15:36:29,311 [mos.py] => cur_adapter.11.up_proj.weight: 12288
2024-01-15 15:36:29,311 [mos.py] => cur_adapter.11.up_proj.bias: 768
2024-01-15 15:36:29,312 [trainer.py] => All params: 86141426
2024-01-15 15:36:29,312 [trainer.py] => Trainable params: 342770
2024-01-15 15:36:29,313 [mos.py] => Learning on 0-10
2024-01-15 15:36:55,818 [mos.py] => Task 0, Epoch 20/20 => Loss 0.109, Train_accy 96.83
2024-01-15 15:37:04,109 [mos.py] => the accuracy of the original model:91.4
2024-01-15 15:37:04,116 [trainer.py] => No NME accuracy.
2024-01-15 15:37:04,116 [trainer.py] => CNN: {'total': 94.2, '00-09': 94.2, 'old': 0, 'new': 94.2}
2024-01-15 15:37:04,116 [trainer.py] => CNN top1 curve: [94.2]
2024-01-15 15:37:04,116 [trainer.py] => CNN top5 curve: [99.7]

2024-01-15 15:37:04,116 [trainer.py] => Average Accuracy (CNN): 94.2 

2024-01-15 15:37:04,117 [trainer.py] => All params: 86453427
2024-01-15 15:37:04,118 [trainer.py] => Trainable params: 342770
2024-01-15 15:37:04,119 [mos.py] => Learning on 10-20
2024-01-15 15:37:32,269 [mos.py] => Task 1, Epoch 20/20 => Loss 0.034, Train_accy 99.08
2024-01-15 15:37:39,273 [mos.py] => Task 1, Epoch 30/30 => Loss 0.004, CA_accy 100.00
2024-01-15 15:37:46,690 [mos.py] => the accuracy of the original model:89.5
2024-01-15 15:37:46,692 [trainer.py] => No NME accuracy.
2024-01-15 15:37:46,692 [trainer.py] => CNN: {'total': 91.57, '00-09': 93.9, '10-19': 85.75, 'old': 93.9, 'new': 85.75}
2024-01-15 15:37:46,693 [trainer.py] => CNN top1 curve: [94.2, 91.57]
2024-01-15 15:37:46,693 [trainer.py] => CNN top5 curve: [99.7, 98.93]

2024-01-15 15:37:46,693 [trainer.py] => Average Accuracy (CNN): 92.88499999999999 

2024-01-15 15:37:46,694 [trainer.py] => All params: 86765427
2024-01-15 15:37:46,696 [trainer.py] => Trainable params: 342770
2024-01-15 15:37:46,697 [mos.py] => Learning on 20-30
2024-01-15 15:38:18,180 [mos.py] => Task 2, Epoch 20/20 => Loss 0.166, Train_accy 96.27
2024-01-15 15:38:26,398 [mos.py] => Task 2, Epoch 30/30 => Loss 0.005, CA_accy 100.00
2024-01-15 15:38:41,553 [mos.py] => the accuracy of the original model:91.45
2024-01-15 15:38:41,555 [trainer.py] => No NME accuracy.
2024-01-15 15:38:41,555 [trainer.py] => CNN: {'total': 92.62, '00-09': 94.1, '10-19': 85.5, '20-29': 94.01, 'old': 91.64, 'new': 94.01}
2024-01-15 15:38:41,555 [trainer.py] => CNN top1 curve: [94.2, 91.57, 92.62]
2024-01-15 15:38:41,555 [trainer.py] => CNN top5 curve: [99.7, 98.93, 99.2]

2024-01-15 15:38:41,555 [trainer.py] => Average Accuracy (CNN): 92.79666666666667 

2024-01-15 15:38:41,556 [trainer.py] => All params: 87077427
2024-01-15 15:38:41,557 [trainer.py] => Trainable params: 342770
2024-01-15 15:38:41,558 [mos.py] => Learning on 30-40
2024-01-15 15:39:55,603 [mos.py] => Task 3, Epoch 20/20 => Loss 0.432, Train_accy 92.30
2024-01-15 15:40:04,972 [mos.py] => Task 3, Epoch 30/30 => Loss 0.015, CA_accy 99.86
2024-01-15 15:41:00,858 [mos.py] => the accuracy of the original model:83.99
2024-01-15 15:41:00,861 [trainer.py] => No NME accuracy.
2024-01-15 15:41:00,861 [trainer.py] => CNN: {'total': 91.93, '00-09': 94.0, '10-19': 85.0, '20-29': 94.11, '30-39': 91.67, 'old': 92.54, 'new': 91.67}
2024-01-15 15:41:00,861 [trainer.py] => CNN top1 curve: [94.2, 91.57, 92.62, 91.93]
2024-01-15 15:41:00,861 [trainer.py] => CNN top5 curve: [99.7, 98.93, 99.2, 99.61]

2024-01-15 15:41:00,861 [trainer.py] => Average Accuracy (CNN): 92.58 

2024-01-15 15:41:00,863 [trainer.py] => All params: 87389427
2024-01-15 15:41:00,864 [trainer.py] => Trainable params: 342770
2024-01-15 15:41:00,865 [mos.py] => Learning on 40-50
2024-01-15 15:41:21,923 [mos.py] => Task 4, Epoch 20/20 => Loss 0.010, Train_accy 100.00
2024-01-15 15:41:30,568 [mos.py] => Task 4, Epoch 30/30 => Loss 0.013, CA_accy 99.92
2024-01-15 15:42:42,720 [mos.py] => the accuracy of the original model:85.49
2024-01-15 15:42:42,724 [trainer.py] => No NME accuracy.
2024-01-15 15:42:42,725 [trainer.py] => CNN: {'total': 92.79, '00-09': 94.7, '10-19': 85.75, '20-29': 94.01, '30-39': 91.65, '40-49': 99.88, 'old': 92.04, 'new': 99.88}
2024-01-15 15:42:42,725 [trainer.py] => CNN top1 curve: [94.2, 91.57, 92.62, 91.93, 92.79]
2024-01-15 15:42:42,725 [trainer.py] => CNN top5 curve: [99.7, 98.93, 99.2, 99.61, 99.71]

2024-01-15 15:42:42,725 [trainer.py] => Average Accuracy (CNN): 92.622 

2024-01-15 15:42:42,726 [trainer.py] => Forgetting (CNN): 0.029999999999997584